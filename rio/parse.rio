fn parse_type_func_param() -> &Typespec {
  let type = parse_type();
  if (match_token(TokenKind.Colon)) {
    if (type.kind != Typespec.Name) {
      error(token.pos, "Colons in parameters of fn types must be preceded by names.");
    }
    type = parse_type();
  }
  return type;
}

fn parse_type_func() -> &Typespec {
  let pos = token.pos;
  let args: *&Typespec = NULL;
  let has_varargs: bool = false;
  expect_token(TokenKind.Lparen);
  while (!is_token(TokenKind.Rparen)) {
    if (match_token(TokenKind.Ellipsis)) {
      if (has_varargs) {
        error(token.pos, "Multiple ellipsis instances in function type");
      }
      has_varargs = true;
    } else {
      if (has_varargs) {
        error(token.pos, "Ellipsis must be last parameter in function type");
      }
      let param = parse_type_func_param();
      buf_push((:*&void)&args, &param, sizeof(param));
    }
    if (!match_token(TokenKind.Comma)) {
      break;
    }
  } while;
  expect_token(TokenKind.Rparen);
  let ret: &Typespec = NULL;
  if (match_token(TokenKind.Arrow)) {
    ret = parse_type();
  }
  return new_typespec_func(pos, args, buf_len(args), ret, has_varargs);
}

fn parse_type_args() -> TypeArgSlice {
  let args: *TypeArg;
  if (match_token(TokenKind.Lt)) {
    do {
      let type_arg = TypeArg{pos = token.pos, val = parse_type()};
      buf_push((:*&void)&args, &type_arg, sizeof(*args));
    } while (match_token(TokenKind.Comma));
    expect_token(TokenKind.Gt);
  }
  return TypeArgSlice{items = args, length = buf_len(args)};
}

fn parse_type_base() -> &Typespec {
  if (is_token(TokenKind.Name)) {
    let pos = token.pos;
    let names: *TypespecName;
    next_token();
    let first_name =
      TypespecName{name = token.name, type_args = parse_type_args()};
    buf_push((:*&void)&names, &first_name, sizeof(first_name));
    while (match_token(TokenKind.Dot)) {
      let name =
        TypespecName{name = parse_name(), type_args = parse_type_args()};
      buf_push((:*&void)&names, &name, sizeof(name));
    }
    let result = new_typespec_name(pos, names, buf_len(names));
    buf_free((:*&void)&names);
    return result;
  } else if (match_keyword(fn_keyword)) {
    return parse_type_func();
  } else if (match_token(TokenKind.Lparen)) {
    let type = parse_type();
    expect_token(TokenKind.Rparen);
    return type;
  } else {
    fatal_error(token.pos, "Unexpected token %s in type", token_info());
    return NULL;
  }
}

fn parse_type() -> &Typespec {
  let pos = token.pos;
  let type: &Typespec;
  // Check modifiers.
  if (match_token(TokenKind.Lbracket)) {
    let size: &Expr = NULL;
    if (!is_token(TokenKind.Rbracket)) {
      size = parse_expr();
    }
    expect_token(TokenKind.Rbracket);
    type = new_typespec_array(pos, parse_type(), size);
  } else if (match_token(TokenKind.And)) {
    type = new_typespec_ref(pos, parse_type(), false);
  } else if (match_token(TokenKind.Mul)) {
    type = new_typespec_ptr(pos, parse_type(), false);
  } else if (match_keyword(const_keyword)) {
    type = new_typespec_const(pos, parse_type());
  } else if (match_keyword(own_keyword)) {
    // TODO Track owning.
    type = parse_type();
  } else {
    type = parse_type_base();
  }
  return type;
}

fn parse_expr_compound_field() -> CompoundField {
  let pos = token.pos;
  if (match_token(TokenKind.Lbracket)) {
    let index = parse_expr();
    expect_token(TokenKind.Rbracket);
    expect_token(TokenKind.Assign);
    return CompoundField {CompoundField.Index, pos, parse_expr(), index = index};
  } else {
    let expr = parse_expr();
    if (match_token(TokenKind.Assign)) {
      if (expr.kind != Expr.Name) {
        fatal_error(token.pos, "Named initializer in compound literal must be preceded by field name");
      }
      return CompoundField {CompoundField.Name, pos, parse_expr(), name = expr.name};
    } else {
      return CompoundField {CompoundField.Default, pos, expr};
    }
  } if;
}

fn parse_expr_compound(type: &Typespec) -> &Expr {
  let pos = token.pos;
  expect_token(TokenKind.Lbrace);
  let fields: *CompoundField = NULL;
  while (!is_token(TokenKind.Rbrace)) {
    let field = parse_expr_compound_field();
    buf_push((:*&void)&fields, &field, sizeof(field));
    if (!match_token(TokenKind.Comma)) {
      break;
    }
  }
  expect_token(TokenKind.Rbrace);
  return new_expr_compound(pos, type, fields, buf_len(fields));
}

fn parse_expr_operand() -> &Expr {
  let pos = token.pos;
  if (is_token(TokenKind.Int)) {
    let val = token.int_val;
    let mod = token.mod;
    let suffix = token.suffix;
    next_token();
    return new_expr_int(pos, val, mod, suffix);
  } else if (is_token(TokenKind.Float)) {
    let start = token.start;
    let end = token.end;
    let val = token.float_val;
    let suffix = token.suffix;
    next_token();
    return new_expr_float(pos, start, end, val, suffix);
  } else if (is_token(TokenKind.Str)) {
    let val = token.str_val;
    let mod = token.mod;
    next_token();
    return new_expr_str(pos, val, mod);
  } else if (is_token(TokenKind.Name)) {
    let name = token.name;
    next_token();
    if (is_token(TokenKind.Lbrace)) {
      return parse_expr_compound(new_typespec_name1(pos, name));
    } else {
      return new_expr_name(pos, name);
    }
  } else if (match_keyword(sizeof_keyword)) {
    expect_token(TokenKind.Lparen);
    if (match_token(TokenKind.Colon)) {
      let type = parse_type();
      expect_token(TokenKind.Rparen);
      return new_expr_sizeof_type(pos, type);
    } else {
      let expr = parse_expr();
      expect_token(TokenKind.Rparen);
      return new_expr_sizeof_expr(pos, expr);
    }
  } else if (match_keyword(alignof_keyword)) {
    expect_token(TokenKind.Lparen);
    if (match_token(TokenKind.Colon)) {
      let type = parse_type();
      expect_token(TokenKind.Rparen);
      return new_expr_alignof_type(pos, type);
    } else {
      let expr = parse_expr();
      expect_token(TokenKind.Rparen);
      return new_expr_alignof_expr(pos, expr);
    }
  } else if (match_keyword(typeof_keyword)) {
    expect_token(TokenKind.Lparen);
    if (match_token(TokenKind.Colon)) {
      let type = parse_type();
      expect_token(TokenKind.Rparen);
      return new_expr_typeof_type(pos, type);
    } else {
      let expr = parse_expr();
      expect_token(TokenKind.Rparen);
      return new_expr_typeof_expr(pos, expr);
    }
  } else if (match_keyword(offsetof_keyword)) {
    expect_token(TokenKind.Lparen);
    let type = parse_type();
    expect_token(TokenKind.Comma);
    let name = parse_name();
    expect_token(TokenKind.Rparen);
    return new_expr_offsetof(pos, type, name);
  } else if (is_token(TokenKind.Lbrace)) {
    return parse_expr_compound(NULL);
  } else if (match_token(TokenKind.Lparen)) {
    if (match_token(TokenKind.Colon)) {
      let type = parse_type();
      expect_token(TokenKind.Rparen);
      if (is_token(TokenKind.Lbrace)) {
        return parse_expr_compound(type);
      } else {
        return new_expr_cast(pos, type, parse_expr_unary());
      }
    } else {
      let expr = parse_expr();
      expect_token(TokenKind.Rparen);
      return new_expr_paren(pos, expr);
    }
  } else {
    fatal_error(token.pos, "Unexpected token %s in expression", token_info());
    return NULL;
  }
}

fn parse_expr_base() -> &Expr {
  let expr = parse_expr_operand();
  while (is_token(TokenKind.Lparen) || is_token(TokenKind.Lbracket) || is_token(TokenKind.Dot) || is_token(TokenKind.Inc) || is_token(TokenKind.Dec)) {
    let pos = token.pos;
    if (match_token(TokenKind.Lparen)) {
      let args: *&Expr = NULL;
      while (!is_token(TokenKind.Rparen)) {
        let arg = parse_expr();
        buf_push((:*&void)&args, &arg, sizeof(arg));
        if (!match_token(TokenKind.Comma)) {
          break;
        }
      }
      expect_token(TokenKind.Rparen);
      expr = new_expr_call(pos, expr, args, buf_len(args));
    } else if (match_token(TokenKind.Lbracket)) {
      let index = parse_expr();
      expect_token(TokenKind.Rbracket);
      expr = new_expr_index(pos, expr, index);
    } else if (is_token(TokenKind.Dot)) {
      next_token();
      let field = token.name;
      expect_token(TokenKind.Name);
      expr = new_expr_field(pos, expr, field);
    } else {
      #assert(is_token(TokenKind.Inc) || is_token(TokenKind.Dec));
      let op = token.kind;
      next_token();
      expr = new_expr_modify(pos, op, true, expr);
    }
  } while;
  return expr;
}

fn is_unary_op() -> bool {
  return
    is_token(TokenKind.Add) ||
    is_token(TokenKind.Sub) ||
    is_token(TokenKind.Mul) ||
    is_token(TokenKind.And) ||
    is_token(TokenKind.Neg) ||
    is_token(TokenKind.Not) ||
    is_token(TokenKind.Inc) ||
    is_token(TokenKind.Dec);
}

fn parse_expr_unary() -> &Expr {
  if (is_unary_op()) {
    let pos = token.pos;
    let op = token.kind;
    next_token();
    if (op == TokenKind.Inc || op == TokenKind.Dec) {
      return new_expr_modify(pos, op, false, parse_expr_unary());
    } else {
      return new_expr_unary(pos, op, parse_expr_unary());
    }
  } else {
    return parse_expr_base();
  }
}

fn is_mul_op() -> bool {
  return TokenKind.FirstMul <= token.kind && token.kind <= TokenKind.LastMul;
}

fn parse_expr_mul() -> &Expr {
  let expr = parse_expr_unary();
  while (is_mul_op()) {
    let pos = token.pos;
    let op = token.kind;
    next_token();
    expr = new_expr_binary(pos, op, expr, parse_expr_unary());
  }
  return expr;
}

fn is_add_op() -> bool {
  return TokenKind.FirstAdd <= token.kind && token.kind <= TokenKind.LastAdd;
}

fn parse_expr_add() -> &Expr {
  let expr = parse_expr_mul();
  while (is_add_op()) {
    let pos = token.pos;
    let op = token.kind;
    next_token();
    expr = new_expr_binary(pos, op, expr, parse_expr_mul());
  }
  return expr;
}

fn is_cmp_op() -> bool {
  return TokenKind.FirstCmp <= token.kind && token.kind <= TokenKind.LastCmp;
}

fn parse_expr_cmp() -> &Expr {
  let expr = parse_expr_add();
  while (is_cmp_op()) {
    let pos = token.pos;
    let op = token.kind;
    next_token();
    expr = new_expr_binary(pos, op, expr, parse_expr_add());
  }
  return expr;
}

fn parse_expr_and() -> &Expr {
  let expr = parse_expr_cmp();
  while (match_token(TokenKind.AndAnd)) {
    let pos = token.pos;
    expr = new_expr_binary(pos, TokenKind.AndAnd, expr, parse_expr_cmp());
  }
  return expr;
}

fn parse_expr_or() -> &Expr {
  let expr = parse_expr_and();
  while (match_token(TokenKind.OrOr)) {
    let pos = token.pos;
    expr = new_expr_binary(pos, TokenKind.OrOr, expr, parse_expr_and());
  }
  return expr;
}

fn parse_expr_ternary() -> &Expr {
  let pos = token.pos;
  let expr = parse_expr_or();
  if (match_token(TokenKind.Question)) {
    let then_expr = parse_expr_ternary();
    expect_token(TokenKind.Colon);
    let else_expr = parse_expr_ternary();
    expr = new_expr_ternary(pos, expr, then_expr, else_expr);
  }
  return expr;
}

fn parse_expr() -> &Expr {
  return parse_expr_ternary();
}

fn parse_paren_expr() -> &Expr {
  expect_token(TokenKind.Lparen);
  let expr = parse_expr();
  expect_token(TokenKind.Rparen);
  return expr;
}

fn parse_stmt_block() -> StmtList {
  let pos = token.pos;
  expect_token(TokenKind.Lbrace);
  let stmts: *&Stmt = NULL;
  while (!is_token_eof() && !is_token(TokenKind.Rbrace)) {
    let stmt = parse_stmt();
    buf_push((:*&void)&stmts, &stmt, sizeof(stmt));
  }
  expect_token(TokenKind.Rbrace);
  return new_stmt_list(pos, stmts, buf_len(stmts));
}

fn parse_stmt_if(pos: SrcPos) -> &Stmt {
  expect_token(TokenKind.Lparen);
  let cond: &Expr;
  let init: &Stmt;
  if (match_keyword(let_keyword)) {
    init = parse_let_stmt(pos);
    if (match_token(TokenKind.Semicolon)) {
      cond = parse_expr();
    }
  } else {
    cond = parse_expr();
  }
  expect_token(TokenKind.Rparen);
  let then_block: StmtList = parse_stmt_block();
  let else_block: StmtList = {{NULL, 0}, NULL, 0};  // TODO Automatic null???
  let elseifs: *ElseIf;
  while (match_keyword(else_keyword)) {
    if (!match_keyword(if_keyword)) {
      else_block = parse_stmt_block();
      break;
    }
    let elseif_cond: &Expr = parse_paren_expr();
    let elseif_block: StmtList = parse_stmt_block();
    let elseif = ElseIf {elseif_cond, elseif_block};
    buf_push((:*&void)&elseifs, &elseif, sizeof(elseif));
  } while;
  return new_stmt_if(pos, init, cond, then_block, elseifs, buf_len(elseifs), else_block);
}

fn parse_stmt_while(pos: SrcPos) -> &Stmt {
  let cond: &Expr = parse_paren_expr();
  return new_stmt_while(pos, cond, parse_stmt_block());
}

fn parse_stmt_do_while(pos: SrcPos) -> &Stmt {
  let block: StmtList = parse_stmt_block();
  if (!match_keyword(while_keyword)) {
    fatal_error(token.pos, "Expected 'while' after 'do' block");
    return NULL;
  }
  let stmt: &Stmt = new_stmt_do_while(pos, parse_paren_expr(), block);
  expect_token(TokenKind.Semicolon);
  return stmt;
}

fn is_assign_op() -> bool {
  return TokenKind.FirstAssign <= token.kind && token.kind <= TokenKind.LastAssign;
}

fn parse_let_stmt(pos: SrcPos) -> &Stmt {
  let is_mut = match_keyword(mut_keyword);
  let name = parse_name();
  if (match_token(TokenKind.Assign)) {
    return new_stmt_init(pos, name, is_mut, NULL, parse_expr());
  } else if (match_token(TokenKind.Colon)) {
    let type = parse_type();
    let expr: &Expr;
    if (match_token(TokenKind.Assign)) {
      expr = parse_expr();
    } else {
      // For now, just let all later assignments slide.
      is_mut = true;
    }
    return new_stmt_init(pos, name, is_mut, type, expr);
  } else {
    fatal_error(token.pos, "Expected : or = after let, got %s", token_info());
    return NULL;
  }
}

fn parse_simple_stmt() -> &Stmt {
  let pos = token.pos;
  let stmt: &Stmt;
  if (match_keyword(let_keyword)) {
    stmt = parse_let_stmt(pos);
  } else {
    let expr = parse_expr();
    if (expr.kind == Expr.Name && match_token(TokenKind.Colon)) {
      stmt = new_stmt_label(pos, expr.name);
    } else if (is_assign_op()) {
      let op = token.kind;
      next_token();
      stmt = new_stmt_assign(pos, op, expr, parse_expr());
    } else {
      stmt = new_stmt_expr(pos, expr);
    }
  }
  return stmt;
}

fn parse_stmt_for(pos: SrcPos) -> &Stmt {
  expect_token(TokenKind.Lparen);
  let init: &Stmt = NULL;
  if (!is_token(TokenKind.Semicolon)) {
    init = parse_simple_stmt();
  }
  expect_token(TokenKind.Semicolon);
  let cond: &Expr = NULL;
  if (!is_token(TokenKind.Semicolon)) {
    cond = parse_expr();
  }
  let next: &Stmt = NULL;
  if (match_token(TokenKind.Semicolon)) {
    if (!is_token(TokenKind.Rparen)) {
      next = parse_simple_stmt();
      if (next.kind == Stmt.Init) {
        error(token.pos, "Init statements not allowed in for-statement's next clause");
      }
    }
  } if;
  expect_token(TokenKind.Rparen);
  return new_stmt_for(pos, init, cond, next, parse_stmt_block());
}

fn parse_switch_case_pattern() -> SwitchCasePattern {
  if (match_keyword(default_keyword)) {
    return SwitchCasePattern {is_default = true};
  }
  let start = parse_expr();
  let end: &Expr;
  if (match_token(TokenKind.Ellipsis)) {
    end = parse_expr();
  }
  return SwitchCasePattern {false, start, end};
}

fn parse_stmt_switch_case() -> SwitchCase {
  let patterns: *SwitchCasePattern;
  let pattern = parse_switch_case_pattern();
  buf_push((:*&void)&patterns, &pattern, sizeof(pattern));
  while (match_token(TokenKind.Comma)) {
    pattern = parse_switch_case_pattern();
    buf_push((:*&void)&patterns, &pattern, sizeof(pattern));
  }
  expect_token(TokenKind.Spear);
  let pos = token.pos;
  let stmt = parse_stmt();
  return SwitchCase {
    patterns, buf_len(patterns), new_stmt_list(pos, &stmt, 1),
  };
}

fn parse_stmt_switch(pos: SrcPos) -> &Stmt {
  let expr: &Expr = parse_paren_expr();
  let cases: *SwitchCase;
  expect_token(TokenKind.Lbrace);
  while (!is_token_eof() && !is_token(TokenKind.Rbrace)) {
    let case_stmt = parse_stmt_switch_case();
    buf_push((:*&void)&cases, &case_stmt, sizeof(case_stmt));
  }
  expect_token(TokenKind.Rbrace);
  return new_stmt_switch(pos, expr, cases, buf_len(cases));
}

fn parse_stmt() -> &Stmt {
  let notes = parse_notes();
  let pos = token.pos;
  let stmt: &Stmt;
  if (match_keyword(if_keyword)) {
    if (match_token(TokenKind.Semicolon)) {
      return new_stmt_close(pos, Stmt.If);
    }
    stmt = parse_stmt_if(pos);
  } else if (match_keyword(while_keyword)) {
    if (match_token(TokenKind.Semicolon)) {
      return new_stmt_close(pos, Stmt.While);
    }
    stmt = parse_stmt_while(pos);
  } else if (match_keyword(do_keyword)) {
    stmt = parse_stmt_do_while(pos);
  } else if (match_keyword(for_keyword)) {
    if (match_token(TokenKind.Semicolon)) {
      return new_stmt_close(pos, Stmt.For);
    }
    stmt = parse_stmt_for(pos);
  } else if (match_keyword(switch_keyword)) {
    if (match_token(TokenKind.Semicolon)) {
      return new_stmt_close(pos, Stmt.Switch);
    }
    stmt = parse_stmt_switch(pos);
  } else if (is_token(TokenKind.Lbrace)) {
    stmt = new_stmt_block(pos, parse_stmt_block());
  } else if (match_keyword(break_keyword)) {
    expect_token(TokenKind.Semicolon);
    stmt = new_stmt_break(pos);
  } else if (match_keyword(continue_keyword)) {
    expect_token(TokenKind.Semicolon);
    stmt = new_stmt_continue(pos);
  } else if (match_keyword(return_keyword)) {
    let expr: &Expr;
    if (!is_token(TokenKind.Semicolon)) {
      expr = parse_expr();
    }
    expect_token(TokenKind.Semicolon);
    stmt = new_stmt_return(pos, expr);
  } else if (match_token(TokenKind.Pound)) {
    let note: Note = parse_note();
    expect_token(TokenKind.Semicolon);
    stmt = new_stmt_note(pos, note);
  } else if (match_keyword(goto_keyword)) {
    stmt = new_stmt_goto(pos, parse_name());
    expect_token(TokenKind.Semicolon);
  } else {
    stmt = parse_simple_stmt();
    if (stmt.kind != Stmt.Label) {
      expect_token(TokenKind.Semicolon);
    }
  }
  stmt.notes = notes;
  return stmt;
}

fn parse_name() -> *const char {
  let name = token.name;
  expect_token(TokenKind.Name);
  return name;
}

fn parse_decl_enum_item() -> EnumItem {
  let pos = token.pos;
  let name = parse_name();
  let init: &Expr = NULL;
  if (match_token(TokenKind.Assign)) {
    init = parse_expr();
  }
  return EnumItem {pos, name, init};
}

fn parse_decl_enum(pos: SrcPos) -> &Decl {
  let name: *const char = NULL;
  if (is_token(TokenKind.Name)) {
    name = parse_name();
  }
  let type: &Typespec = NULL;
  if (match_token(TokenKind.Assign)) {
    type = parse_type();
  }
  expect_token(TokenKind.Lbrace);
  let items: *EnumItem = NULL;
  while (!is_token(TokenKind.Rbrace)) {
    let item = parse_decl_enum_item();
    buf_push((:*&void)&items, &item, sizeof(item));
    if (!match_token(TokenKind.Comma)) {
      break;
    }
  }
  expect_token(TokenKind.Rbrace);
  return new_decl_enum(pos, name, type, items, buf_len(items));
}

fn parse_decl_aggregate_item() -> AggregateItem {
  let pos = token.pos;
  if (match_keyword(struct_keyword)) {
    return AggregateItem {
      pos = pos,
      kind = AggregateItem.Subaggregate,
      subaggregate = parse_aggregate(AggregateKind.Struct, NULL, NULL),
    };
  } else if (match_keyword(union_keyword)) {
    return AggregateItem {
      pos = pos,
      kind = AggregateItem.Subaggregate,
      subaggregate = parse_aggregate(AggregateKind.Union, NULL, NULL),
    };
  } else {
    let names: **const char = NULL;
    let name = parse_name();
    buf_push((:*&void)&names, &name, sizeof(name));
    while (match_token(TokenKind.Comma)) {
      name = parse_name();
      buf_push((:*&void)&names, &name, sizeof(name));
    }
    expect_token(TokenKind.Colon);
    let type = parse_type();
    expect_token(TokenKind.Semicolon);
    return AggregateItem {
      pos = pos,
      kind = AggregateItem.Field,
      names = names,
      num_names = buf_len(names),
      type = type,
    };
  } if;
}

let enum_tag_names = (:[]*const char) {"kind"};
let enum_tag_name_interned = false;

fn parse_aggregate(
  kind: AggregateKind, name: *const char, notes: &Notes,
) -> &Aggregate {
  let pos = token.pos;
  let items: *AggregateItem;
  let has_enum = false;
  let enum_union: &Aggregate;
  if (match_keyword(switch_keyword)) {
    if (kind != AggregateKind.Union) {
      fatal_error(pos, "Switch aggregate applies only to union");
    }
    items = parse_switch_union();
    has_enum = true;
  } else {
    expect_token(TokenKind.Lbrace);
    while (!is_token_eof() && !is_token(TokenKind.Rbrace)) {
      let item = parse_decl_aggregate_item();
      buf_push((:*&void)&items, &item, sizeof(item));
      // See if it's a switch union.
      if (item.kind == AggregateItem.Subaggregate) {
        let sub = item.subaggregate;
        if (sub.kind == AggregateKind.Union && sub.num_items) {
          if (sub.items.num_kind_names) {
            // But only one subunion here is allowed.
            if (enum_union) {
              fatal_error(sub.pos, "Multiple switch unions in struct");
              return NULL;
            }
            enum_union = sub;
          } if;
        } if;
      } if;
    } while;
    expect_token(TokenKind.Rbrace);
    if (notes && get_note(notes, enum_keyword)) {
      has_enum = true;
    }
  } if;
  // Check for enum union conditions.
  // TODO Change conditions for enum union. Like has a switch union.
  // TODO Then default to enum union.
  if (name && (has_enum || enum_union)) {
    if (kind == AggregateKind.Union) {
      // This is the union. Contain it.
      enum_union = new_aggregate(pos, kind, items, buf_len(items));
      let subitem = AggregateItem {
        pos = pos,
        kind = AggregateItem.Subaggregate,
        subaggregate = enum_union,
      };
      // Wrap it in a struct.
      kind = AggregateKind.Struct;
      items = NULL;
      buf_push((:*&void)&items, &subitem, sizeof(subitem));
    } else if (!enum_union) {
      enum_union = get_subunion(buf_len(items), items);
      if (!enum_union) {
        fatal_error(pos, "No union for enum tag");
        return NULL;
      }
    }
    // Insert the new kind member to the struct at the top.
    // TODO Do we know up front to avoid this after the fact insertion?
    if (!enum_tag_name_interned) {
      enum_tag_names[0] = str_intern(enum_tag_names[0]);
      enum_tag_name_interned = true;
    }
    let tag_type_name = build_scoped_name(name, "Kind");
    let tag_item = AggregateItem {
      pos = pos,
      kind = AggregateItem.Field,
      names = enum_tag_names,
      num_names = 1,
      type = new_typespec_name(pos, &TypespecName{name = tag_type_name}, 1),
    };
    buf_unshift((:*&void)&items, &tag_item, sizeof(tag_item));
    // Create and attach union enum.
    // TODO Then use that elsewhere instead of having to recheck notes.
    build_enum_union_decl(enum_union, name);
  } if;
  let result = new_aggregate(pos, kind, items, buf_len(items));
  if (enum_union) {
    // Remember this at top for easy access later.
    result.union_enum_decl = enum_union.union_enum_decl;
  }
  return result;
}

let empty_names = (:[]*const char) {""};

fn parse_switch_union() -> *AggregateItem {
  expect_token(TokenKind.Lbrace);
  let items: *AggregateItem;
  while (!is_token_eof() && !is_token(TokenKind.Rbrace)) {
    let kind_names: **const char;
    let kind_name = parse_name();
    buf_push((:*&void)&kind_names, &kind_name, sizeof(kind_name));
    // TODO Ellipse ranges.
    while (match_token(TokenKind.Comma)) {
      kind_name = parse_name();
      buf_push((:*&void)&kind_names, &kind_name, sizeof(kind_name));
    }
    expect_token(TokenKind.Spear);
    let pos = token.pos;
    let item: AggregateItem;
    if (match_token(TokenKind.Colon)) {
      let type = parse_type();
      if (!(
        type.kind == Typespec.Name &&
        type.num_names == 1 &&
        type.names[0].name == void_name
      )) {
        fatal_error(token.pos, "Anonymous switch fields can only be void");
        return NULL;
      }
      expect_token(TokenKind.Semicolon);
      item = AggregateItem {
        pos = pos,
        kind = AggregateItem.Field,
        names = empty_names,
        num_names = 1,
        type = type,
      };
    } else {
      item = parse_decl_aggregate_item();
      if (item.kind == AggregateItem.Field && item.num_names != 1) {
        fatal_error(item.pos, "Switch union field requires exactly one name");
        return NULL;
      }
    }
    item.kind_names = kind_names;
    item.num_kind_names = buf_len(kind_names);
    buf_push((:*&void)&items, &item, sizeof(item));
  } while;
  expect_token(TokenKind.Rbrace);
  return items;
}

fn build_enum_union_decl(enum_union: &Aggregate, decl_name: *const char) {
  // TODO Extract function.
  // Lowercase enum because we can't have a union member named enum, at least
  // not without escaping, so this uses a less likely collision, even if it's
  // a lowercase typename.
  let enum_type_name = build_scoped_name(decl_name, "Kind");
  let num_items = enum_union.num_items;
  // let {num_items} = enum_union;
  // Figure out how many items we really have.
  let num_all_items: usize = 0;
  for (let i: usize = 0; i < num_items; ++i) {
    let union_item = &enum_union.items[i];
    let num_names = union_item.num_kind_names;
    if (!num_names) {
      // Non-switch enum union.
      if (union_item.kind != AggregateItem.Field) {
        fatal_error(
          union_item.pos, "Enum union item of %s not a field", decl_name,
        );
        return;
      }
      num_names = union_item.num_names;
    } if;
    num_all_items += num_names;
  } for;
  // Now build the enum items.
  let enum_items = (:*EnumItem)xmalloc(num_all_items * sizeof(EnumItem));
  let enum_item_index: usize = 0;
  for (let i: usize = 0; i < num_items; ++i) {
    let union_item = &enum_union.items[i];
    let num_names = union_item.num_kind_names;
    let names = union_item.kind_names;
    if (!num_names) {
      // Non switch.
      num_names = union_item.num_names;
      names = union_item.names;
    }
    for (let n: usize = 0; n < num_names; ++n) {
      enum_items[enum_item_index++] = EnumItem {
        pos = union_item.pos, name = names[n], init = NULL,
      };
    } for;
  } for;
  // And add the new enum.
  let union_enum_decl = new_decl_enum(
    enum_union.pos, enum_type_name, NULL, enum_items, num_all_items,
  );
  enum_union.union_enum_decl = union_enum_decl;
}

fn parse_decl_aggregate(pos: SrcPos, kind: Decl.Kind, notes: &Notes) -> &Decl {
  #assert(kind == Decl.Struct || kind == Decl.Union);
  let name = parse_name();
  let aggregate_kind =
    kind == Decl.Struct ? AggregateKind.Struct : AggregateKind.Union;
  let params: DeclSlice;
  if (match_token(TokenKind.Lt)) {
    while (!match_token(TokenKind.Gt)) {
      let param_name = parse_name();
      // TODO Parse type constraints and defaults.
      let param = Decl {
        kind = Decl.Typedef,
        pos = token.pos,
        name = param_name,
        typedef_decl = {constraint = new_typespec_name1(token.pos, void_name)},
        // Let val default to null.
      };
      buf_push((:*&void)&params.items, &param, sizeof(param));
    }
    params.length = buf_len(params.items);
  }
  if (match_token(TokenKind.Semicolon)) {
    let decl = new_decl_aggregate(
      pos, kind, name, params, new_aggregate(pos, aggregate_kind, NULL, 0),
    );
    decl.is_incomplete = true;
    return decl;
  } else {
    return new_decl_aggregate(
      pos, kind, name, params, parse_aggregate(aggregate_kind, name, notes),
    );
  }
}

fn parse_decl_var(pos: SrcPos) -> &Decl {
  let name = parse_name();
  if (match_token(TokenKind.Assign)) {
    let expr = parse_expr();
    expect_token(TokenKind.Semicolon);
    return new_decl_var(pos, name, NULL, expr);
  } else if (match_token(TokenKind.Colon)) {
    let type = parse_type();
    let expr: &Expr = NULL;
    if (match_token(TokenKind.Assign)) {
      expr = parse_expr();
    }
    expect_token(TokenKind.Semicolon);
    return new_decl_var(pos, name, type, expr);
  } else {
    fatal_error(token.pos, "Expected : or = after let, got %s", token_info());
    return NULL;
  }
}

fn parse_decl_const(pos: SrcPos) -> &Decl {
  let name = parse_name();
  let type: &Typespec = NULL;
  if (match_token(TokenKind.Colon)) {
    type = parse_type();
  }
  expect_token(TokenKind.Assign);
  let expr = parse_expr();
  expect_token(TokenKind.Semicolon);
  return new_decl_const(pos, name, type, expr);
}

fn parse_decl_typedef(pos: SrcPos) -> &Decl {
  let name = parse_name();
  expect_token(TokenKind.Assign);
  let type = parse_type();
  expect_token(TokenKind.Semicolon);
  return new_decl_typedef(pos, name, type);
}

fn parse_decl_func_param() -> FuncParam {
  let pos = token.pos;
  let name = parse_name();
  // TODO Default args.
  expect_token(TokenKind.Colon);
  let type = parse_type();
  return FuncParam {pos, name, type};
}

fn parse_decl_func(pos: SrcPos) -> &Decl {
  let name = parse_name();
  expect_token(TokenKind.Lparen);
  let params: *FuncParam = NULL;
  let has_varargs: bool = false;
  while (!is_token(TokenKind.Rparen)) {
    if (match_token(TokenKind.Ellipsis)) {
      if (has_varargs) {
        error(token.pos, "Multiple ellipsis in function declaration");
      }
      has_varargs = true;
    } else {
      if (has_varargs) {
        error(token.pos, "Ellipsis must be last parameter in function declaration");
      }
      let param = parse_decl_func_param();
      buf_push((:*&void)&params, &param, sizeof(param));
    }
    if (!match_token(TokenKind.Comma)) {
      break;
    }
  } while;
  expect_token(TokenKind.Rparen);
  let ret_type: &Typespec = NULL;
  if (match_token(TokenKind.Arrow)) {
    ret_type = parse_type();
  }
  let block: StmtList;  // TODO Auto initialized? = {0};
  let is_incomplete: bool;
  if (match_token(TokenKind.Semicolon)) {
    is_incomplete = true;
  } else {
    block = parse_stmt_block();
    is_incomplete = false;
  }
  let decl = new_decl_func(
    pos, name, params, buf_len(params), ret_type, has_varargs, block,
  );
  decl.is_incomplete = is_incomplete;
  return decl;
}

fn parse_note_arg() -> NoteArg {
  let pos = token.pos;
  let expr = parse_expr();
  let name: *const char = NULL;
  if (match_token(TokenKind.Assign)) {
    if (expr.kind != Expr.Name) {
      fatal_error(token.pos, "Left of: operand = in note argument must be a name");
    }
    name = expr.name;
    expr = parse_expr();
  }
  return NoteArg {pos = pos, name = name, expr = expr};
}

fn parse_note() -> Note {
  let pos = token.pos;
  let name: *const char;
  if (is_token(TokenKind.Keyword)) {
    name = token.name;
    next_token();
  } else {
    name = parse_name();
  }
  let args: *NoteArg = NULL;
  if (match_token(TokenKind.Lparen)) {
    let arg = parse_note_arg();
    buf_push((:*&void)&args, &arg, sizeof(arg));
    while (match_token(TokenKind.Comma)) {
      arg = parse_note_arg();
      buf_push((:*&void)&args, &arg, sizeof(arg));
    }
    expect_token(TokenKind.Rparen);
  } if;
  return new_note(pos, name, args, buf_len(args));
}

fn parse_notes() -> Notes {
  let notes: *Note = NULL;
  while (match_token(TokenKind.At)) {
    let note = parse_note();
    buf_push((:*&void)&notes, &note, sizeof(note));
  }
  return new_notes(notes, buf_len(notes));
}

fn parse_decl_note(pos: SrcPos) -> &Decl {
  return new_decl_note(pos, parse_note());
}

fn parse_decl_import(pos: SrcPos) -> &Decl {
  let rename_name: *const char;
  let is_relative: bool;
  repeat:
  is_relative = false;
  if (match_token(TokenKind.Dot)) {
    is_relative = true;
  }
  let name = token.name;
  expect_token(TokenKind.Name);
  if (!is_relative && match_token(TokenKind.Assign)) {
    if (rename_name) {
      fatal_error(pos, "Only one import assignment is allowed");
    }
    rename_name = name;
    goto repeat;
  }
  let names: **const char = NULL;
  buf_push((:*&void)&names, &name, sizeof(name));
  while (match_token(TokenKind.Dot)) {
    buf_push((:*&void)&names, &token.name, sizeof(token.name));
    expect_token(TokenKind.Name);
  }
  let import_all = false;
  let items: *ImportItem;
  if (match_token(TokenKind.Lbrace)) {
    while (!is_token(TokenKind.Rbrace)) {
      if (match_token(TokenKind.Ellipsis)) {
        import_all = true;
      } else {
        let item_name = parse_name();
        if (match_token(TokenKind.Assign)) {
          let item = ImportItem {name = parse_name(), rename = item_name};
          buf_push((:*&void)&items, &item, sizeof(item));
        } else {
          let item = ImportItem {name = item_name};
          buf_push((:*&void)&items, &item, sizeof(item));
        }
        if (!match_token(TokenKind.Comma)) {
          break;
        }
      } if;
    } while;
    expect_token(TokenKind.Rbrace);
  } if;
  return new_decl_import(pos, rename_name, is_relative, names, buf_len(names), import_all, items, buf_len(items));
}

fn parse_decl_opt(notes: &Notes) -> &Decl {
  let pos = token.pos;
  if (match_keyword(enum_keyword)) {
    return parse_decl_enum(pos);
  } else if (match_keyword(struct_keyword)) {
    return parse_decl_aggregate(pos, Decl.Struct, notes);
  } else if (match_keyword(union_keyword)) {
    return parse_decl_aggregate(pos, Decl.Union, notes);
  } else if (match_keyword(const_keyword)) {
    return parse_decl_const(pos);
  } else if (match_keyword(typedef_keyword)) {
    return parse_decl_typedef(pos);
  } else if (match_keyword(fn_keyword)) {
    return parse_decl_func(pos);
  } else if (match_keyword(let_keyword)) {
    return parse_decl_var(pos);
  } else if (match_keyword(import_keyword)) {
    return parse_decl_import(pos);
  } else if (match_token(TokenKind.Pound)) {
    return parse_decl_note(pos);
  } else {
    return NULL;
  }
}

fn parse_decl() -> &Decl {
  let notes = parse_notes();
  let decl: &Decl = parse_decl_opt(&notes);
  if (!decl) {
    fatal_error(token.pos, "Expected declaration keyword, got %s", token_info());
  }
  decl.notes = notes;
  return decl;
}

fn parse_decls() -> &Decls {
  let decls: *&Decl = NULL;
  while (!is_token(TokenKind.Eof)) {
    let decl = parse_decl();
    buf_push((:*&void)&decls, &decl, sizeof(decl));
  }
  return new_decls(decls, buf_len(decls));
}
