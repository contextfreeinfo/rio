let typedef_keyword: *const char;
let enum_keyword: *const char;
let struct_keyword: *const char;
let union_keyword: *const char;
let let_keyword: *const char;
let mut_keyword: *const char;
let own_keyword: *const char;
let const_keyword: *const char;
let fn_keyword: *const char;
let sizeof_keyword: *const char;
let alignof_keyword: *const char;
let typeof_keyword: *const char;
let offsetof_keyword: *const char;
let break_keyword: *const char;
let continue_keyword: *const char;
let return_keyword: *const char;
let if_keyword: *const char;
let else_keyword: *const char;
let while_keyword: *const char;
let do_keyword: *const char;
let for_keyword: *const char;
let switch_keyword: *const char;
let case_keyword: *const char;
let default_keyword: *const char;
let import_keyword: *const char;
let goto_keyword: *const char;

let first_keyword: *const char;
let last_keyword: *const char;
let keywords: **const char;

let always_name: *const char;
let foreign_name: *const char;
let unscoped_name: *const char;
let complete_name: *const char;
let assert_name: *const char;
let declare_note_name: *const char;
let static_assert_name: *const char;

let void_name: *const char;

// #define KEYWORD(name) name##_keyword = str_intern(#name); buf_push(keywords, name##_keyword)
fn init_keyword(keyword: *const char) -> *const char {
  keyword = str_intern(keyword);
  // TODO If rio doesn't give warnings, the underlying compiler also shouldn't.
  buf_push((:&&void)&keywords, (:&void)&keyword, sizeof(keyword));
  return keyword;
}

let keywords_inited = false;

fn init_keywords() {
  if (keywords_inited) {
    return;
  }
  typedef_keyword = init_keyword("typedef");
  let arena_end: *char = intern_arena.end;
  enum_keyword = init_keyword("enum");
  struct_keyword = init_keyword("struct");
  union_keyword = init_keyword("union");
  const_keyword = init_keyword("const");
  let_keyword = init_keyword("let");
  mut_keyword = init_keyword("mut");
  own_keyword = init_keyword("own");
  fn_keyword = init_keyword("fn");
  import_keyword = init_keyword("import");
  goto_keyword = init_keyword("goto");
  sizeof_keyword = init_keyword("sizeof");
  alignof_keyword = init_keyword("alignof");
  typeof_keyword = init_keyword("typeof");
  offsetof_keyword = init_keyword("offsetof");
  break_keyword = init_keyword("break");
  continue_keyword = init_keyword("continue");
  return_keyword = init_keyword("return");
  if_keyword = init_keyword("if");
  else_keyword = init_keyword("else");
  while_keyword = init_keyword("while");
  do_keyword = init_keyword("do");
  for_keyword = init_keyword("for");
  switch_keyword = init_keyword("switch");
  case_keyword = init_keyword("case");
  default_keyword = init_keyword("default");
  #assert(intern_arena.end == arena_end);
  first_keyword = typedef_keyword;
  last_keyword = default_keyword;

  always_name = str_intern("always");
  foreign_name = str_intern("foreign");
  unscoped_name = str_intern("unscoped");
  complete_name = str_intern("complete");
  assert_name = str_intern("assert");
  declare_note_name = str_intern("declare_note");
  static_assert_name = str_intern("static_assert");

  void_name = str_intern("void");

  keywords_inited = true;
}

// #undef KEYWORD

fn is_keyword_name(name: *const char) -> bool {
  return first_keyword <= name && name <= last_keyword;
}

enum TokenKind {
  Eof,
  Colon,
  Arrow,
  Spear,
  Lparen,
  Rparen,
  Lbrace,
  Rbrace,
  Lbracket,
  Rbracket,
  Comma,
  Dot,
  At,
  Pound,
  Ellipsis,
  Question,
  Semicolon,
  Keyword,
  Int,
  Float,
  Str,
  Name,
  Neg,
  Not,
  // Multiplicative precedence
  FirstMul,
  Mul = TokenKind.FirstMul,
  Div,
  Mod,
  And,
  Lshift,
  Rshift,
  LastMul = TokenKind.Rshift,
  // Additive precedence
  FirstAdd,
  Add = TokenKind.FirstAdd,
  Sub,
  Xor,
  Or,
  LastAdd = TokenKind.Or,
  // Comparative precedence
  FirstCmp,
  Eq = TokenKind.FirstCmp,
  NotEq,
  Lt,
  Gt,
  LtEq,
  GtEq,
  LastCmp = TokenKind.GtEq,
  AndAnd,
  OrOr,
  // Assignment operators
  FirstAssign,
  Assign = TokenKind.FirstAssign,
  AddAssign,
  SubAssign,
  OrAssign,
  AndAssign,
  XorAssign,
  LshiftAssign,
  RshiftAssign,
  MulAssign,
  DivAssign,
  ModAssign,
  LastAssign = TokenKind.ModAssign,
  Inc,
  Dec,
  Num,
}

enum TokenMod {
  None,
  Hex,
  Bin,
  Oct,
  Char,
  Multiline,
}

enum TokenSuffix {
  None,
  D,
  U,
  L,
  UL,
  LL,
  ULL,
}

let token_suffix_names: []*const char = {
  [TokenSuffix.None] = "",
  [TokenSuffix.D] = "d",
  [TokenSuffix.U] = "u",
  [TokenSuffix.L] = "l",
  [TokenSuffix.UL] = "ul",
  [TokenSuffix.LL] = "ll",
  [TokenSuffix.ULL] = "ull",
};

let token_kind_names: []*const char = {
  [TokenKind.Eof] = "EOF",
  [TokenKind.Colon] = ":",
  [TokenKind.Arrow] = "->",
  [TokenKind.Spear] = "=>",
  [TokenKind.Lparen] = "(",
  [TokenKind.Rparen] = ")",
  [TokenKind.Lbrace] = "{",
  [TokenKind.Rbrace] = "}",
  [TokenKind.Lbracket] = "[",
  [TokenKind.Rbracket] = "]",
  [TokenKind.Comma] = ",",
  [TokenKind.Dot] = ".",
  [TokenKind.At] = "@",
  [TokenKind.Pound] = "#",
  [TokenKind.Ellipsis] = "...",
  [TokenKind.Question] = "?",
  [TokenKind.Semicolon] = ";",
  [TokenKind.Keyword] = "keyword",
  [TokenKind.Int] = "int",
  [TokenKind.Float] = "float",
  [TokenKind.Str] = "string",
  [TokenKind.Name] = "name",
  [TokenKind.Neg] = "~",
  [TokenKind.Not] = "!",
  [TokenKind.Mul] = "*",
  [TokenKind.Div] = "/",
  [TokenKind.Mod] = "%",
  [TokenKind.And] = "&",
  [TokenKind.Lshift] = "<<",
  [TokenKind.Rshift] = ">>",
  [TokenKind.Add] = "+",
  [TokenKind.Sub] = "-",
  [TokenKind.Or] = "|",
  [TokenKind.Xor] = "^",
  [TokenKind.Eq] = "==",
  [TokenKind.NotEq] = "!=",
  [TokenKind.Lt] = "<",
  [TokenKind.Gt] = ">",
  [TokenKind.LtEq] = "<=",
  [TokenKind.GtEq] = ">=",
  [TokenKind.AndAnd] = "&&",
  [TokenKind.OrOr] = "||",
  [TokenKind.Assign] = "=",
  [TokenKind.AddAssign] = "+=",
  [TokenKind.SubAssign] = "-=",
  [TokenKind.OrAssign] = "|=",
  [TokenKind.AndAssign] = "&=",
  [TokenKind.XorAssign] = "^=",
  [TokenKind.MulAssign] = "*=",
  [TokenKind.DivAssign] = "/=",
  [TokenKind.ModAssign] = "%=",
  [TokenKind.LshiftAssign] = "<<=",
  [TokenKind.RshiftAssign] = ">>=",
  [TokenKind.Inc] = "++",
  [TokenKind.Dec] = "--",
};

fn token_kind_name(kind: TokenKind) -> *const char {
  if (kind < sizeof(token_kind_names)/sizeof(*token_kind_names)) {
    return token_kind_names[kind];
  } else {
    return "<unknown>";
  }
}

let assign_token_to_binary_token: [TokenKind.Num]TokenKind = {
  [TokenKind.AddAssign] = TokenKind.Add,
  [TokenKind.SubAssign] = TokenKind.Sub,
  [TokenKind.OrAssign] = TokenKind.Or,
  [TokenKind.AndAssign] = TokenKind.And,
  [TokenKind.XorAssign] = TokenKind.Xor,
  [TokenKind.LshiftAssign] = TokenKind.Lshift,
  [TokenKind.RshiftAssign] = TokenKind.Rshift,
  [TokenKind.MulAssign] = TokenKind.Mul,
  [TokenKind.DivAssign] = TokenKind.Div,
  [TokenKind.ModAssign] = TokenKind.Mod,
};

struct SrcPos {
  name: *const char;
  line: int;
}

let pos_builtin: SrcPos = {name = "<builtin>"};

struct Token {
  kind: TokenKind;
  mod: TokenMod;
  suffix: TokenSuffix;
  pos: SrcPos;
  start: *const char;
  end: *const char;
  // Not @tagged?, very many to one
  union {
    int_val: ullong;
    float_val: double;
    str_val: *const char;
    name: *const char;
  }
}

let token: Token;
let stream: *const char;
let line_start: *const char;

fn vnotice(level: *const char, pos: SrcPos, fmt: *const char, args: va_list) {
  if (pos.name == NULL) {
    pos = pos_builtin;
  }
  printf("%s(%d): %s: ", pos.name, pos.line, level);
  vprintf(fmt, args);
  printf("\n");
}

fn warning(pos: SrcPos, fmt: *const char, ...) {
  let args: va_list;
  va_start(&args, &fmt);
  vnotice("warning", pos, fmt, args);
  va_end(&args);
}

fn verror(pos: SrcPos, fmt: *const char, args: va_list) {
  vnotice("error", pos, fmt, args);
}

fn error(pos: SrcPos, fmt: *const char, ...) {
  let args: va_list;
  va_start(&args, &fmt);
  verror(pos, fmt, args);
  va_end(&args);
}

fn fatal_error(pos: SrcPos, fmt: *const char, ...) {
  let args: va_list;
  va_start(&args, &fmt);
  verror(pos, fmt, args);
  va_end(&args);
  exit(1);
}

// #define fatal_error(...) (error(__VA_ARGS__), exit(1))
// #define error(token.pos, ...) (error(token.pos, __VA_ARGS__))
// #define warning_here(...) (error(token.pos, __VA_ARGS__))
// #define fatal_error(token.pos, ...) (error(token.pos, __VA_ARGS__), exit(1))

fn token_info() -> *const char {
  if (token.kind == TokenKind.Name || token.kind == TokenKind.Keyword) {
    return token.name;
  } else {
    return token_kind_name(token.kind);
  }
}

let char_to_digit: [256]uint8 = {
  ['0'] = 0,
  ['1'] = 1,
  ['2'] = 2,
  ['3'] = 3,
  ['4'] = 4,
  ['5'] = 5,
  ['6'] = 6,
  ['7'] = 7,
  ['8'] = 8,
  ['9'] = 9,
  ['a'] = 10, ['A'] = 10,
  ['b'] = 11, ['B'] = 11,
  ['c'] = 12, ['C'] = 12,
  ['d'] = 13, ['D'] = 13,
  ['e'] = 14, ['E'] = 14,
  ['f'] = 15, ['F'] = 15,
};

fn scan_int() {
  let base = 10;
  let start_digits = stream;
  if (*stream == '0') {
    stream++;
    if (tolower(*stream) == 'x') {
      stream++;
      token.mod = TokenMod.Hex;
      base = 16;
      start_digits = stream;
    } else if (tolower(*stream) == 'b') {
      stream++;
      token.mod = TokenMod.Bin;
      base = 2;
      start_digits = stream;
    } else if (isdigit(*stream)) {
      token.mod = TokenMod.Oct;
      base = 8;
      start_digits = stream;
    }
  }
  let val: ullong = 0;
  for (;;) {
    if (*stream == '_') {
      stream++;
      continue;
    }
    let digit = char_to_digit[(:uchar)*stream];
    if (digit == 0 && *stream != '0') {
      break;
    }
    if (digit >= base) {
      error(token.pos, "Digit '%c' out of range for base %d", *stream, base);
      digit = 0;
    }
    if (val > (ULLONG_MAX - digit)/base) {
      error(token.pos, "Integer literal overflow");
      while (isdigit(*stream)) {
        stream++;
      }
      val = 0;
      break;
    }
    val = val * base + digit;
    stream++;
  }
  if (stream == start_digits) {
    error(token.pos, "Expected base %d digit, got '%c'", base, *stream);
  }
  token.kind = TokenKind.Int;
  token.int_val = val;
  if (tolower(*stream) == 'u') {
    token.suffix = TokenSuffix.U;
    stream++;
    if (tolower(*stream) == 'l') {
      token.suffix = TokenSuffix.UL;
      stream++;
      if (tolower(*stream) == 'l') {
        token.suffix = TokenSuffix.ULL;
        stream++;
      }
    }
  } else if (tolower(*stream) == 'l') {
    token.suffix = TokenSuffix.L;
    stream++;
    if (tolower(*stream) == 'l') {
      token.suffix = TokenSuffix.LL;
      stream++;
    }
  }
}

// TODO Why do I have to give a value, and is it used??? I hope not.
@foreign const HUGE_VAL = 0.0;

fn scan_float() {
  let start = stream;
  while (isdigit(*stream)) {
    stream++;
  }
  if (*stream == '.') {
    stream++;
  }
  while (isdigit(*stream)) {
    stream++;
  }
  if (tolower(*stream) == 'e') {
    stream++;
    if (*stream == '+' || *stream == '-') {
      stream++;
    }
    if (!isdigit(*stream)) {
      error(token.pos, "Expected digit after float literal exponent, found '%c'.", *stream);
    }
    while (isdigit(*stream)) {
      stream++;
    }
  }
  let val = strtod(start, NULL);
  if (val == HUGE_VAL) {
    error(token.pos, "Float literal overflow");
  }
  token.kind = TokenKind.Float;
  token.float_val = val;
  if (tolower(*stream) == 'd') {
    token.suffix = TokenSuffix.D;
    stream++;
  }
}

let escape_to_char: [256]char = {
  ['0'] = '\0',
  ['\''] = '\'',
  ['"'] = '"',
  ['\\'] = '\\',
  ['n'] = '\n',
  ['r'] = '\r',
  ['t'] = '\t',
  ['v'] = '\v',
  ['b'] = '\b',
  ['a'] = '\a',
};

fn scan_hex_escape() -> int {
  #assert(*stream == 'x');
  stream++;
  let val = char_to_digit[(:uchar)*stream];
  if (!val && *stream != '0') {
    error(token.pos, "\\x needs at least 1 hex digit");
  }
  stream++;
  let digit = char_to_digit[(:uchar)*stream];
  if (digit || *stream == '0') {
    val *= 16;
    val += digit;
    if (val > 0xFF) {
      error(token.pos, "\\x argument out of range");
      val = 0xFF;
    }
    stream++;
  }
  return val;
}

fn scan_char() {
  #assert(*stream == '\'');
  stream++;
  let val = 0;
  if (*stream == '\'') {
    error(token.pos, "Char literal cannot be empty");
    stream++;
  } else if (*stream == '\n') {
    error(token.pos, "Char literal cannot contain newline");
  } else if (*stream == '\\') {
    stream++;
    if (*stream == 'x') {
      val = scan_hex_escape();
    } else {
      val = escape_to_char[(:uchar)*stream];
      if (val == 0 && *stream != '0') {
        error(token.pos, "Invalid char literal escape '\\%c'", *stream);
      }
      stream++;
    }
  } else {
    val = *stream;
    stream++;
  }
  if (*stream != '\'') {
    error(token.pos, "Expected closing char quote, got '%c'", *stream);
  } else {
    stream++;
  }
  token.kind = TokenKind.Int;
  token.int_val = val;
  token.mod = TokenMod.Char;
}

fn scan_str() {
  #assert(*stream == '"');
  stream++;
  let str: *char = NULL;
  if (stream[0] == '"' && stream[1] == '"') {
    stream += 2;
    while (*stream) {
      if (stream[0] == '"' && stream[1] == '"' && stream[2] == '"') {
        stream += 3;
        break;
      }
      if (*stream != '\r') {
        // TODO: Should probably just read files in text mode instead.
        buf_push((:&&void)&str, (:&void)stream, 1);
      }
      if (*stream == '\n') {
        token.pos.line++;
      }
      stream++;
    }
    if (!*stream) {
      error(token.pos, "Unexpected end of file within multi-line string literal");
    }
    token.mod = TokenMod.Multiline;
  } else {
    while (*stream && *stream != '"') {
      let val = *stream;
      if (val == '\n') {
        error(token.pos, "String literal cannot contain newline");
        break;
      } else if (val == '\\') {
        stream++;
        if (*stream == 'x') {
          val = scan_hex_escape();
        } else {
          val = escape_to_char[(:uchar)*stream];
          if (val == 0 && *stream != '0') {
            error(token.pos, "Invalid string literal escape '\\%c'", *stream);
          }
          stream++;
        }
      } else {
        stream++;
      }
      buf_push((:&&void)&str, &val, 1);
    }
    if (*stream) {
      stream++;
    } else {
      error(token.pos, "Unexpected end of file within string literal");
    }
  }
  // TODO: If I say just "", I get a random byte in the c output from c rio.
  let nul = '\0';
  buf_push((:&&void)&str, &nul, 1);
  token.kind = TokenKind.Str;
  token.str_val = str;
}

// These CASE macros are reminders of what the C code used to look like, in case
// an acceptable macro implementation in rio comes along.

// #define CASE1(c1, k1) \
//   case c1: \
//     token.kind = k1; \
//     stream++; \
//     break;

// #define CASE2(c1, k1, c2, k2) \
//   case c1: \
//     token.kind = k1; \
//     stream++; \
//     if (*stream == c2) { \
//       token.kind = k2; \
//       stream++; \
//     } \
//     break;

// #define CASE3(c1, k1, c2, k2, c3, k3) \
//   case c1: \
//     token.kind = k1; \
//     stream++; \
//     if (*stream == c2) { \
//       token.kind = k2; \
//       stream++; \
//     } else if (*stream == c3) { \
//       token.kind = k3; \
//       stream++; \
//     } \
//     break;

fn next_token() {
  repeat:
  token.start = stream;
  token.mod = 0;
  token.suffix = 0;
  switch (*stream) {
    ' ', '\n', '\r', '\t', '\v' => {
      while (isspace(*stream)) {
        if (*stream++ == '\n') {
          line_start = stream;
          token.pos.line++;
        }
      }
      goto repeat;
    }
    '\'' => scan_char();
    '"' => scan_str();
    '.' => {
      if (isdigit(stream[1])) {
        scan_float();
      } else if (stream[1] == '.' && stream[2] == '.') {
        token.kind = TokenKind.Ellipsis;
        stream += 3;
      } else {
        token.kind = TokenKind.Dot;
        stream++;
      }
    }
    '0' ... '9' => {
      while (isdigit(*stream)) {
        stream++;
      }
      let c = *stream;
      stream = token.start;
      if (c == '.' || tolower(c) == 'e') {
        scan_float();
      } else {
        scan_int();
      }
    }
    'a' ... 'z', 'A' ... 'Z', '_' => {
      while (isalnum(*stream) || *stream == '_') {
        stream++;
      }
      token.name = str_intern_range(token.start, stream);
      token.kind =
        is_keyword_name(token.name) ? TokenKind.Keyword : TokenKind.Name;
    }
    '<' => {
      token.kind = TokenKind.Lt;
      stream++;
      if (*stream == '<') {
        token.kind = TokenKind.Lshift;
        stream++;
        if (*stream == '=') {
          token.kind = TokenKind.LshiftAssign;
          stream++;
        }
      } else if (*stream == '=') {
        token.kind = TokenKind.LtEq;
        stream++;
      }
    }
    '>' => {
      token.kind = TokenKind.Gt;
      stream++;
      if (*stream == '>') {
        token.kind = TokenKind.Rshift;
        stream++;
        if (*stream == '=') {
          token.kind = TokenKind.RshiftAssign;
          stream++;
        }
      } else if (*stream == '=') {
        token.kind = TokenKind.GtEq;
        stream++;
      }
    }
    '/' => {
      token.kind = TokenKind.Div;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.DivAssign;
        stream++;
      } else if (*stream == '/') {
        stream++;
        while (*stream && *stream != '\n') {
          stream++;
        }
        goto repeat;
      } else if (*stream == '*') {
        stream++;
        let level = 1;
        while (*stream && level > 0) {
          if (stream[0] == '/' && stream[1] == '*') {
            level++;
            stream += 2;
          } else if (stream[0] == '*' && stream[1] == '/') {
            level--;
            stream += 2;
          } else {
            if (*stream == '\n') {
              token.pos.line++;
            }
            stream++;
          }
        }
        goto repeat;
      }
    }
    // CASE1 --
    // TODO Could build a reverse mapping on these from token_kind_names, then
    // TODO use that as a lookup.
    '\0' => {
      token.kind = TokenKind.Eof;
      stream++;
    }
    '(' => {
      token.kind = TokenKind.Lparen;
      stream++;
    }
    ')' => {
      token.kind = TokenKind.Rparen;
      stream++;
    }
    '{' => {
      token.kind = TokenKind.Lbrace;
      stream++;
    }
    '}' => {
      token.kind = TokenKind.Rbrace;
      stream++;
    }
    '[' => {
      token.kind = TokenKind.Lbracket;
      stream++;
    }
    ']' => {
      token.kind = TokenKind.Rbracket;
      stream++;
    }
    ',' => {
      token.kind = TokenKind.Comma;
      stream++;
    }
    '@' => {
      token.kind = TokenKind.At;
      stream++;
    }
    '#' => {
      token.kind = TokenKind.Pound;
      stream++;
    }
    '?' => {
      token.kind = TokenKind.Question;
      stream++;
    }
    ';' => {
      token.kind = TokenKind.Semicolon;
      stream++;
    }
    '~' => {
      token.kind = TokenKind.Neg;
      stream++;
    }
    // CASE2 --
    '!' => {
      token.kind = TokenKind.Not;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.NotEq;
        stream++;
      }
    }
    ':' => {
      token.kind = TokenKind.Colon;
      stream++;
    }
    '=' => {
      token.kind = TokenKind.Assign;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.Eq;
        stream++;
      } else if (*stream == '>') {
        token.kind = TokenKind.Spear;
        ++stream;
      }
    }
    '^' => {
      token.kind = TokenKind.Xor;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.XorAssign;
        stream++;
      }
    }
    '*' => {
      token.kind = TokenKind.Mul;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.MulAssign;
        stream++;
      }
    }
    '%' => {
      token.kind = TokenKind.Mod;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.ModAssign;
        stream++;
      }
    }
    // CASE3 --
    '+' => {
      token.kind = TokenKind.Add;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.AddAssign;
        stream++;
      } else if (*stream == '+') {
        token.kind = TokenKind.Inc;
        stream++;
      }
    }
    '-' => {
      token.kind = TokenKind.Sub;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.SubAssign;
        stream++;
      } else if (*stream == '-') {
        token.kind = TokenKind.Dec;
        stream++;
      } else if (*stream == '>') {
        token.kind = TokenKind.Arrow;
        stream++;
      }
    }
    '&' => {
      token.kind = TokenKind.And;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.AndAssign;
        stream++;
      } else if (*stream == '&') {
        token.kind = TokenKind.AndAnd;
        stream++;
      }
    }
    '|' => {
      token.kind = TokenKind.Or;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.OrAssign;
        stream++;
      } else if (*stream == '|') {
        token.kind = TokenKind.OrOr;
        stream++;
      }
    }
    default => {
      error(token.pos, "Invalid '%c' token, skipping", *stream);
      stream++;
      goto repeat;
    }
  }
  token.end = stream;
}

// #undef CASE1
// #undef CASE2
// #undef CASE3

fn init_stream(name: *const char, buf: *const char) {
  stream = buf;
  line_start = stream;
  token.pos.name = name ? name : (:*const char)"<string>";
  token.pos.line = 1;
  next_token();
}

fn is_token(kind: TokenKind) -> bool {
  return token.kind == kind;
}

fn is_token_eof() -> bool {
  return token.kind == TokenKind.Eof;
}

fn is_token_name(name: *const char) -> bool {
  return token.kind == TokenKind.Name && token.name == name;
}

fn is_keyword(name: *const char) -> bool {
  return is_token(TokenKind.Keyword) && token.name == name;
}

fn match_keyword(name: *const char) -> bool {
  if (is_keyword(name)) {
    next_token();
    return true;
  } else {
    return false;
  }
}

fn match_token(kind: TokenKind) -> bool {
  if (is_token(kind)) {
    next_token();
    return true;
  } else {
    return false;
  }
}

fn expect_token(kind: TokenKind) -> bool {
  if (is_token(kind)) {
    next_token();
    return true;
  } else {
    fatal_error(token.pos, "Expected token %s, got %s", token_kind_name(kind), token_info());
    return false;
  }
}
