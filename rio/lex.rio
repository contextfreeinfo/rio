let typedef_keyword: *const char;
let enum_keyword: *const char;
let struct_keyword: *const char;
let union_keyword: *const char;
let let_keyword: *const char;
let mut_keyword: *const char;
let own_keyword: *const char;
let const_keyword: *const char;
let def_keyword: *const char;
let sizeof_keyword: *const char;
let alignof_keyword: *const char;
let typeof_keyword: *const char;
let offsetof_keyword: *const char;
let break_keyword: *const char;
let continue_keyword: *const char;
let return_keyword: *const char;
let if_keyword: *const char;
let else_keyword: *const char;
let while_keyword: *const char;
let do_keyword: *const char;
let for_keyword: *const char;
let switch_keyword: *const char;
let case_keyword: *const char;
let default_keyword: *const char;
let import_keyword: *const char;
let goto_keyword: *const char;

let first_keyword: *const char;
let last_keyword: *const char;
let keywords: **const char;

let as_name: *const char;
let always_name: *const char;
let foreign_name: *const char;
let unscoped_name: *const char;
let complete_name: *const char;
let assert_name: *const char;
let declare_note_name: *const char;
let static_assert_name: *const char;

let void_name: *const char;

// #define KEYWORD(name) name##_keyword = str_intern(#name); buf_push(keywords, name##_keyword)
def init_keyword(keyword: *const char) -> *const char {
  keyword = str_intern(keyword);
  // TODO If rio doesn't give warnings, the underlying compiler also shouldn't.
  buf_push(&keywords as &&void, &keyword as &void, sizeof(keyword));
  return keyword;
}

let keywords_inited = false;

def init_keywords() {
  if (keywords_inited) {
    return;
  }
  typedef_keyword = init_keyword("typedef");
  let arena_end: *char = intern_arena.end;
  enum_keyword = init_keyword("enum");
  struct_keyword = init_keyword("struct");
  union_keyword = init_keyword("union");
  const_keyword = init_keyword("const");
  let_keyword = init_keyword("let");
  mut_keyword = init_keyword("mut");
  own_keyword = init_keyword("own");
  def_keyword = init_keyword("def");
  import_keyword = init_keyword("import");
  goto_keyword = init_keyword("goto");
  sizeof_keyword = init_keyword("sizeof");
  alignof_keyword = init_keyword("alignof");
  typeof_keyword = init_keyword("typeof");
  offsetof_keyword = init_keyword("offsetof");
  break_keyword = init_keyword("break");
  continue_keyword = init_keyword("continue");
  return_keyword = init_keyword("return");
  if_keyword = init_keyword("if");
  else_keyword = init_keyword("else");
  while_keyword = init_keyword("while");
  do_keyword = init_keyword("do");
  for_keyword = init_keyword("for");
  switch_keyword = init_keyword("switch");
  case_keyword = init_keyword("case");
  default_keyword = init_keyword("default");
  #assert(intern_arena.end == arena_end);
  first_keyword = typedef_keyword;
  last_keyword = default_keyword;

  as_name = str_intern("as");
  always_name = str_intern("always");
  foreign_name = str_intern("foreign");
  unscoped_name = str_intern("unscoped");
  complete_name = str_intern("complete");
  assert_name = str_intern("assert");
  declare_note_name = str_intern("declare_note");
  static_assert_name = str_intern("static_assert");
  // TODO static_print or static_log or something.

  void_name = str_intern("void");

  keywords_inited = true;
}

// #undef KEYWORD

def is_keyword_name(name: *const char) -> bool {
  return first_keyword <= name && name <= last_keyword;
}

enum TokenKind {
  Eof,
  Colon,
  Arrow,
  Spear,
  Lparen,
  Rparen,
  Lbrace,
  Rbrace,
  Lbracket,
  Rbracket,
  Comma,
  Dot,
  At,
  Pound,
  Ellipsis,
  Question,
  Semicolon,
  Keyword,
  Int,
  Float,
  Str,
  Name,
  Neg,
  Not,
  // Multiplicative precedence
  FirstMul,
  Mul = TokenKind.FirstMul,
  Div,
  Mod,
  And,
  Lshift,
  Rshift,
  LastMul = TokenKind.Rshift,
  // Additive precedence
  FirstAdd,
  Add = TokenKind.FirstAdd,
  Sub,
  Xor,
  Or,
  LastAdd = TokenKind.Or,
  // Comparative precedence
  FirstCmp,
  Eq = TokenKind.FirstCmp,
  NotEq,
  Lt,
  Gt,
  LtEq,
  GtEq,
  LastCmp = TokenKind.GtEq,
  AndAnd,
  OrOr,
  // Assignment operators
  FirstAssign,
  Assign = TokenKind.FirstAssign,
  AddAssign,
  SubAssign,
  OrAssign,
  AndAssign,
  XorAssign,
  LshiftAssign,
  RshiftAssign,
  MulAssign,
  DivAssign,
  ModAssign,
  LastAssign = TokenKind.ModAssign,
  Inc,
  Dec,
  Num,
}

enum TokenMod {
  None,
  Hex,
  Bin,
  Oct,
  Char,
  Multiline,
}

enum TokenSuffix {
  None,
  D,
  U,
  L,
  UL,
  LL,
  ULL,
}

let token_suffix_names: []*const char = [
  TokenSuffix.None: "",
  TokenSuffix.D: "d",
  TokenSuffix.U: "u",
  TokenSuffix.L: "l",
  TokenSuffix.UL: "ul",
  TokenSuffix.LL: "ll",
  TokenSuffix.ULL: "ull",
];

let token_kind_names: []*const char = [
  TokenKind.Eof: "EOF",
  TokenKind.Colon: ":",
  TokenKind.Arrow: "->",
  TokenKind.Spear: "=>",
  TokenKind.Lparen: "(",
  TokenKind.Rparen: ")",
  TokenKind.Lbrace: "{",
  TokenKind.Rbrace: "}",
  TokenKind.Lbracket: "[",
  TokenKind.Rbracket: "]",
  TokenKind.Comma: ",",
  TokenKind.Dot: ".",
  TokenKind.At: "@",
  TokenKind.Pound: "#",
  TokenKind.Ellipsis: "...",
  TokenKind.Question: "?",
  TokenKind.Semicolon: ";",
  TokenKind.Keyword: "keyword",
  TokenKind.Int: "int",
  TokenKind.Float: "float",
  TokenKind.Str: "string",
  TokenKind.Name: "name",
  TokenKind.Neg: "~",
  TokenKind.Not: "!",
  TokenKind.Mul: "*",
  TokenKind.Div: "/",
  TokenKind.Mod: "%",
  TokenKind.And: "&",
  TokenKind.Lshift: "<<",
  TokenKind.Rshift: ">>",
  TokenKind.Add: "+",
  TokenKind.Sub: "-",
  TokenKind.Or: "|",
  TokenKind.Xor: "^",
  TokenKind.Eq: "==",
  TokenKind.NotEq: "!=",
  TokenKind.Lt: "<",
  TokenKind.Gt: ">",
  TokenKind.LtEq: "<=",
  TokenKind.GtEq: ">=",
  TokenKind.AndAnd: "&&",
  TokenKind.OrOr: "||",
  TokenKind.Assign: "=",
  TokenKind.AddAssign: "+=",
  TokenKind.SubAssign: "-=",
  TokenKind.OrAssign: "|=",
  TokenKind.AndAssign: "&=",
  TokenKind.XorAssign: "^=",
  TokenKind.MulAssign: "*=",
  TokenKind.DivAssign: "/=",
  TokenKind.ModAssign: "%=",
  TokenKind.LshiftAssign: "<<=",
  TokenKind.RshiftAssign: ">>=",
  TokenKind.Inc: "++",
  TokenKind.Dec: "--",
];

def token_kind_name(kind: TokenKind) -> *const char {
  if (kind < sizeof(token_kind_names)/sizeof(*token_kind_names)) {
    return token_kind_names[kind];
  } else {
    return "<unknown>";
  }
}

let assign_token_to_binary_token: [TokenKind.Num]TokenKind = [
  TokenKind.AddAssign: TokenKind.Add,
  TokenKind.SubAssign: TokenKind.Sub,
  TokenKind.OrAssign: TokenKind.Or,
  TokenKind.AndAssign: TokenKind.And,
  TokenKind.XorAssign: TokenKind.Xor,
  TokenKind.LshiftAssign: TokenKind.Lshift,
  TokenKind.RshiftAssign: TokenKind.Rshift,
  TokenKind.MulAssign: TokenKind.Mul,
  TokenKind.DivAssign: TokenKind.Div,
  TokenKind.ModAssign: TokenKind.Mod,
];

struct SrcPos {
  name: *const char;
  line: int;
}

let pos_builtin: SrcPos = {name: "<builtin>"};

struct Token {
  kind: TokenKind;
  mod: TokenMod;
  suffix: TokenSuffix;
  pos: SrcPos;
  start: *const char;
  end: *const char;
  // Not @tagged?, very many to one
  union {
    int_val: ullong;
    float_val: double;
    str_val: *const char;
    name: *const char;
  }
}

let token: Token;
let stream: *const char;
let line_start: *const char;

def vnotice(level: *const char, pos: SrcPos, fmt: *const char, args: va_list) {
  if (pos.name == NULL) {
    pos = pos_builtin;
  }
  printf("%s(%d): %s: ", pos.name, pos.line, level);
  vprintf(fmt, args);
  printf("\n");
}

def warning(pos: SrcPos, fmt: *const char, ...) {
  let args: va_list;
  va_start(&args, &fmt);
  vnotice("warning", pos, fmt, args);
  va_end(&args);
}

def verror(pos: SrcPos, fmt: *const char, args: va_list) {
  vnotice("error", pos, fmt, args);
}

def error(pos: SrcPos, fmt: *const char, ...) {
  let args: va_list;
  va_start(&args, &fmt);
  verror(pos, fmt, args);
  va_end(&args);
}

def fatal_error(pos: SrcPos, fmt: *const char, ...) {
  let args: va_list;
  va_start(&args, &fmt);
  verror(pos, fmt, args);
  va_end(&args);
  exit(1);
}

// #define fatal_error(...) (error(__VA_ARGS__), exit(1))
// #define error(token.pos, ...) (error(token.pos, __VA_ARGS__))
// #define warning_here(...) (error(token.pos, __VA_ARGS__))
// #define fatal_error(token.pos, ...) (error(token.pos, __VA_ARGS__), exit(1))

def token_info() -> *const char {
  if (token.kind == TokenKind.Name || token.kind == TokenKind.Keyword) {
    return token.name;
  } else {
    return token_kind_name(token.kind);
  }
}

let char_to_digit: [256]uint8 = [
  '0': 0,
  '1': 1,
  '2': 2,
  '3': 3,
  '4': 4,
  '5': 5,
  '6': 6,
  '7': 7,
  '8': 8,
  '9': 9,
  'a': 10, 'A': 10,
  'b': 11, 'B': 11,
  'c': 12, 'C': 12,
  'd': 13, 'D': 13,
  'e': 14, 'E': 14,
  'f': 15, 'F': 15,
];

def scan_int() {
  let base = 10;
  let start_digits = stream;
  if (*stream == '0') {
    stream++;
    if (tolower(*stream) == 'x') {
      stream++;
      token.mod = TokenMod.Hex;
      base = 16;
      start_digits = stream;
    } else if (tolower(*stream) == 'b') {
      stream++;
      token.mod = TokenMod.Bin;
      base = 2;
      start_digits = stream;
    } else if (isdigit(*stream)) {
      token.mod = TokenMod.Oct;
      base = 8;
      start_digits = stream;
    }
  }
  let val: ullong = 0;
  for (;;) {
    if (*stream == '_') {
      stream++;
      continue;
    }
    let digit = char_to_digit[*stream as uchar];
    if (digit == 0 && *stream != '0') {
      break;
    }
    if (digit >= base) {
      error(token.pos, "Digit '%c' out of range for base %d", *stream, base);
      digit = 0;
    }
    if (val > (ULLONG_MAX - digit)/base) {
      error(token.pos, "Integer literal overflow");
      while (isdigit(*stream)) {
        stream++;
      }
      val = 0;
      break;
    }
    val = val * base + digit;
    stream++;
  }
  if (stream == start_digits) {
    error(token.pos, "Expected base %d digit, got '%c'", base, *stream);
  }
  token.kind = TokenKind.Int;
  token.int_val = val;
  if (tolower(*stream) == 'u') {
    token.suffix = TokenSuffix.U;
    stream++;
    if (tolower(*stream) == 'l') {
      token.suffix = TokenSuffix.UL;
      stream++;
      if (tolower(*stream) == 'l') {
        token.suffix = TokenSuffix.ULL;
        stream++;
      }
    }
  } else if (tolower(*stream) == 'l') {
    token.suffix = TokenSuffix.L;
    stream++;
    if (tolower(*stream) == 'l') {
      token.suffix = TokenSuffix.LL;
      stream++;
    }
  }
}

// TODO Why do I have to give a value, and is it used??? I hope not.
@foreign const HUGE_VAL = 0.0;

def scan_float() {
  let start = stream;
  while (isdigit(*stream)) {
    stream++;
  }
  if (*stream == '.') {
    stream++;
  }
  while (isdigit(*stream)) {
    stream++;
  }
  if (tolower(*stream) == 'e') {
    stream++;
    if (*stream == '+' || *stream == '-') {
      stream++;
    }
    if (!isdigit(*stream)) {
      error(token.pos, "Expected digit after float literal exponent, found '%c'.", *stream);
    }
    while (isdigit(*stream)) {
      stream++;
    }
  }
  let val = strtod(start, NULL);
  if (val == HUGE_VAL) {
    error(token.pos, "Float literal overflow");
  }
  token.kind = TokenKind.Float;
  token.float_val = val;
  if (tolower(*stream) == 'd') {
    token.suffix = TokenSuffix.D;
    stream++;
  }
}

let escape_to_char: [256]char = [
  '0': '\0',
  '\'': '\'',
  '"': '"',
  '\\': '\\',
  'n': '\n',
  'r': '\r',
  't': '\t',
  'v': '\v',
  'b': '\b',
  'a': '\a',
];

def scan_hex_escape() -> int {
  #assert(*stream == 'x');
  stream++;
  let val = char_to_digit[*stream as uchar];
  if (!val && *stream != '0') {
    error(token.pos, "\\x needs at least 1 hex digit");
  }
  stream++;
  let digit = char_to_digit[*stream as uchar];
  if (digit || *stream == '0') {
    val *= 16;
    val += digit;
    if (val > 0xFF) {
      error(token.pos, "\\x argument out of range");
      val = 0xFF;
    }
    stream++;
  }
  return val;
}

def scan_char() {
  #assert(*stream == '\'');
  stream++;
  let val = 0;
  if (*stream == '\'') {
    error(token.pos, "Char literal cannot be empty");
    stream++;
  } else if (*stream == '\n') {
    error(token.pos, "Char literal cannot contain newline");
  } else if (*stream == '\\') {
    stream++;
    if (*stream == 'x') {
      val = scan_hex_escape();
    } else {
      val = escape_to_char[*stream as uchar];
      if (val == 0 && *stream != '0') {
        error(token.pos, "Invalid char literal escape '\\%c'", *stream);
      }
      stream++;
    }
  } else {
    val = *stream;
    stream++;
  }
  if (*stream != '\'') {
    error(token.pos, "Expected closing char quote, got '%c'", *stream);
  } else {
    stream++;
  }
  token.kind = TokenKind.Int;
  token.int_val = val;
  token.mod = TokenMod.Char;
}

def scan_str() {
  #assert(*stream == '"');
  stream++;
  let str: *char = NULL;
  if (stream[0] == '"' && stream[1] == '"') {
    stream += 2;
    while (*stream) {
      if (stream[0] == '"' && stream[1] == '"' && stream[2] == '"') {
        stream += 3;
        break;
      }
      if (*stream != '\r') {
        // TODO: Should probably just read files in text mode instead.
        buf_push(&str as &&void, stream as &void, 1);
      }
      if (*stream == '\n') {
        token.pos.line++;
      }
      stream++;
    }
    if (!*stream) {
      error(token.pos, "Unexpected end of file within multi-line string literal");
    }
    token.mod = TokenMod.Multiline;
  } else {
    while (*stream && *stream != '"') {
      let val = *stream;
      if (val == '\n') {
        error(token.pos, "String literal cannot contain newline");
        break;
      } else if (val == '\\') {
        stream++;
        if (*stream == 'x') {
          val = scan_hex_escape();
        } else {
          val = escape_to_char[*stream as uchar];
          if (val == 0 && *stream != '0') {
            error(token.pos, "Invalid string literal escape '\\%c'", *stream);
          }
          stream++;
        }
      } else {
        stream++;
      }
      buf_push(&str as &&void, &val, 1);
    }
    if (*stream) {
      stream++;
    } else {
      error(token.pos, "Unexpected end of file within string literal");
    }
  }
  // TODO: If I say just "", I get a random byte in the c output from c rio.
  let nul = '\0';
  buf_push(&str as &&void, &nul, 1);
  token.kind = TokenKind.Str;
  token.str_val = str;
}

// These CASE macros are reminders of what the C code used to look like, in case
// an acceptable macro implementation in rio comes along.

// #define CASE1(c1, k1) \
//   case c1: \
//     token.kind = k1; \
//     stream++; \
//     break;

// #define CASE2(c1, k1, c2, k2) \
//   case c1: \
//     token.kind = k1; \
//     stream++; \
//     if (*stream == c2) { \
//       token.kind = k2; \
//       stream++; \
//     } \
//     break;

// #define CASE3(c1, k1, c2, k2, c3, k3) \
//   case c1: \
//     token.kind = k1; \
//     stream++; \
//     if (*stream == c2) { \
//       token.kind = k2; \
//       stream++; \
//     } else if (*stream == c3) { \
//       token.kind = k3; \
//       stream++; \
//     } \
//     break;

def next_token() {
  repeat:
  token.start = stream;
  token.mod = 0;
  token.suffix = 0;
  switch (*stream) {
    ' ', '\n', '\r', '\t', '\v' => {
      while (isspace(*stream)) {
        if (*stream++ == '\n') {
          line_start = stream;
          token.pos.line++;
        }
      }
      goto repeat;
    }
    '\'' => scan_char();
    '"' => scan_str();
    '.' => {
      if (isdigit(stream[1])) {
        scan_float();
      } else if (stream[1] == '.' && stream[2] == '.') {
        token.kind = TokenKind.Ellipsis;
        stream += 3;
      } else {
        token.kind = TokenKind.Dot;
        stream++;
      }
    }
    '0' ... '9' => {
      while (isdigit(*stream)) {
        stream++;
      }
      let c = *stream;
      stream = token.start;
      if (c == '.' || tolower(c) == 'e') {
        scan_float();
      } else {
        scan_int();
      }
    }
    'a' ... 'z', 'A' ... 'Z', '_' => {
      while (isalnum(*stream) || *stream == '_') {
        stream++;
      }
      token.name = str_intern_range(token.start, stream);
      token.kind =
        is_keyword_name(token.name) ? TokenKind.Keyword : TokenKind.Name;
    }
    '<' => {
      token.kind = TokenKind.Lt;
      stream++;
      if (*stream == '<') {
        token.kind = TokenKind.Lshift;
        stream++;
        if (*stream == '=') {
          token.kind = TokenKind.LshiftAssign;
          stream++;
        }
      } else if (*stream == '=') {
        token.kind = TokenKind.LtEq;
        stream++;
      }
    }
    '>' => {
      token.kind = TokenKind.Gt;
      stream++;
      if (*stream == '>') {
        token.kind = TokenKind.Rshift;
        stream++;
        if (*stream == '=') {
          token.kind = TokenKind.RshiftAssign;
          stream++;
        }
      } else if (*stream == '=') {
        token.kind = TokenKind.GtEq;
        stream++;
      }
    }
    '/' => {
      token.kind = TokenKind.Div;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.DivAssign;
        stream++;
      } else if (*stream == '/') {
        stream++;
        while (*stream && *stream != '\n') {
          stream++;
        }
        goto repeat;
      } else if (*stream == '*') {
        stream++;
        let level = 1;
        while (*stream && level > 0) {
          if (stream[0] == '/' && stream[1] == '*') {
            level++;
            stream += 2;
          } else if (stream[0] == '*' && stream[1] == '/') {
            level--;
            stream += 2;
          } else {
            if (*stream == '\n') {
              token.pos.line++;
            }
            stream++;
          }
        }
        goto repeat;
      }
    }
    // CASE1 --
    // TODO Could build a reverse mapping on these from token_kind_names, then
    // TODO use that as a lookup.
    '\0' => {
      token.kind = TokenKind.Eof;
      stream++;
    }
    '(' => {
      token.kind = TokenKind.Lparen;
      stream++;
    }
    ')' => {
      token.kind = TokenKind.Rparen;
      stream++;
    }
    '{' => {
      token.kind = TokenKind.Lbrace;
      stream++;
    }
    '}' => {
      token.kind = TokenKind.Rbrace;
      stream++;
    }
    '[' => {
      token.kind = TokenKind.Lbracket;
      stream++;
    }
    ']' => {
      token.kind = TokenKind.Rbracket;
      stream++;
    }
    ',' => {
      token.kind = TokenKind.Comma;
      stream++;
    }
    '@' => {
      token.kind = TokenKind.At;
      stream++;
    }
    '#' => {
      token.kind = TokenKind.Pound;
      stream++;
    }
    '?' => {
      token.kind = TokenKind.Question;
      stream++;
    }
    ';' => {
      token.kind = TokenKind.Semicolon;
      stream++;
    }
    '~' => {
      token.kind = TokenKind.Neg;
      stream++;
    }
    // CASE2 --
    '!' => {
      token.kind = TokenKind.Not;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.NotEq;
        stream++;
      }
    }
    ':' => {
      token.kind = TokenKind.Colon;
      stream++;
    }
    '=' => {
      token.kind = TokenKind.Assign;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.Eq;
        stream++;
      } else if (*stream == '>') {
        token.kind = TokenKind.Spear;
        ++stream;
      }
    }
    '^' => {
      token.kind = TokenKind.Xor;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.XorAssign;
        stream++;
      }
    }
    '*' => {
      token.kind = TokenKind.Mul;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.MulAssign;
        stream++;
      }
    }
    '%' => {
      token.kind = TokenKind.Mod;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.ModAssign;
        stream++;
      }
    }
    // CASE3 --
    '+' => {
      token.kind = TokenKind.Add;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.AddAssign;
        stream++;
      } else if (*stream == '+') {
        token.kind = TokenKind.Inc;
        stream++;
      }
    }
    '-' => {
      token.kind = TokenKind.Sub;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.SubAssign;
        stream++;
      } else if (*stream == '-') {
        token.kind = TokenKind.Dec;
        stream++;
      } else if (*stream == '>') {
        token.kind = TokenKind.Arrow;
        stream++;
      }
    }
    '&' => {
      token.kind = TokenKind.And;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.AndAssign;
        stream++;
      } else if (*stream == '&') {
        token.kind = TokenKind.AndAnd;
        stream++;
      }
    }
    '|' => {
      token.kind = TokenKind.Or;
      stream++;
      if (*stream == '=') {
        token.kind = TokenKind.OrAssign;
        stream++;
      } else if (*stream == '|') {
        token.kind = TokenKind.OrOr;
        stream++;
      }
    }
    default => {
      error(token.pos, "Invalid '%c' token, skipping", *stream);
      stream++;
      goto repeat;
    }
  }
  token.end = stream;
}

// #undef CASE1
// #undef CASE2
// #undef CASE3

def init_stream(name: *const char, buf: *const char) {
  stream = buf;
  line_start = stream;
  token.pos.name = name ? name : "<string>" as *const char;
  token.pos.line = 1;
  next_token();
}

def is_token(kind: TokenKind) -> bool {
  return token.kind == kind;
}

def is_token_eof() -> bool {
  return token.kind == TokenKind.Eof;
}

def is_token_name(name: *const char) -> bool {
  return token.kind == TokenKind.Name && token.name == name;
}

def is_keyword(name: *const char) -> bool {
  return is_token(TokenKind.Keyword) && token.name == name;
}

def match_keyword(name: *const char) -> bool {
  if (is_keyword(name)) {
    next_token();
    return true;
  } else {
    return false;
  }
}

def expect_close_angle() -> bool {
  if (is_token(TokenKind.Rshift)) {
    // Hack to support >> as two close angle brackets.
    ++token.start;
    token.kind = TokenKind.Gt;
    return true;
  } else {
    return expect_token(TokenKind.Gt);
  }
}

def match_token(kind: TokenKind) -> bool {
  if (is_token(kind)) {
    next_token();
    return true;
  } else {
    return false;
  }
}

def expect_token(kind: TokenKind) -> bool {
  if (is_token(kind)) {
    next_token();
    return true;
  } else {
    fatal_error(token.pos, "Expected token %s, got %s", token_kind_name(kind), token_info());
    return false;
  }
}
